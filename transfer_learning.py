# -*- coding: utf-8 -*-
"""transfer-learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TzoV35wW0Wyuk2_S5TIug-G9y9VAQluB
"""

!unzip /content/DATA/307169_625423_bundle_archive.zip

from keras.applications import VGG16 

img_rows = 224
img_cols = 224

model= VGG16(weights= 'imagenet', include_top = False, input_shape= (img_rows, img_cols,3))

for i in model.layers:
  i.trainable=False
  print(i.__class__.__name__,'=',i.trainable)

from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D
from keras.layers.normalization import BatchNormalization
from keras.models import Model

top = model.output
top = Flatten(name = 'flatten')(top)
top = Dense(512, activation='relu')(top)
top = Dense(256,activation='relu')(top)
top = Dropout(0.3)(top)
top = Dense(14,activation='softmax')(top)

model.input

model.layers[:10]

model = Model(inputs = model.input, outputs= top)

model.summary()

from keras.preprocessing.image import ImageDataGenerator

train_data_dir = '/content/14-celebrity-faces-dataset/data/train'
validation_data_dir = '/content/14-celebrity-faces-dataset/data/val'

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest')

validation_datagen = ImageDataGenerator(rescale=1./255)

#change the batch size accordingly to RAM
train_batchsize=16
val_batchsize= 10

train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size= (224,224),
    batch_size= train_batchsize,
    class_mode= 'categorical')
    
validation_generator = validation_datagen.flow_from_directory(
    validation_data_dir,
    target_size= (224,224),
    batch_size= val_batchsize,
    class_mode= 'categorical',
    shuffle=False)

from keras.optimizers import RMSprop
from keras.callbacks import ModelCheckpoint, EarlyStopping

checkpoint = ModelCheckpoint("FaceDetect.h5",
                             monitor="val_loss",
                             mode="min",
                             save_best_only= True,
                             verbose=1)
earlystop = EarlyStopping(monitor = 'val_loss',
                          min_delta= 0,
                          patience = 3,
                          verbose=1,
                          restore_best_weights = True)
callbacks = [earlystop, checkpoint]

model.compile (loss = 'categorical_crossentropy',
               optimizer = RMSprop(lr=0.001),
               metrics = ['accuracy'])

history = model.fit_generator(
    train_generator,
    steps_per_epoch =100,
    epochs = 20,
    callbacks = callbacks,
    validation_data = validation_generator,
    validation_steps = 70//7
)

model.save("FaceDetect.h5")

from keras.models import load_model

classifier = load_model('FaceDetect.h5')

import os
import cv2
import numpy as np
from os import listdir
from os.path import isfile, join

face_detect_dict = {"[0]":"anne_hathaway",
                    "[1]":"arnold_schwarzenegger",
                    "[2]": "ben_afflek",
                    "[3]": "dwayne_johnson",
                    "[4]":"elton_john",
                    "[5]":"jerry_seinfeld",
                    "[6]":"kate_neckinsale",
                    "[7]":"keanu_reeves",
                    "[8]":"lauren_cohan",
                    "[9]":"madonna",
                    "[10]":"mindy_kaling",
                    "[11]":"simon_pegg",
                    "[12]":"sofia_vergara",
                    "[13]":"will smith"}

face_detect_dict_n = { "anne_hathaway": "anne_hathaway",
                      "arnold_schwarzenegger":"arnold_schwarzenegger",
                      "ben_afflek": "ben_afflek",
                      "dwayne_johnson": "dwayne_johnson",
                      "elton_john":"elton_john",
                      "jerry_seinfeld":"jerry_seinfeld",
                      "kate_neckinsale":"kate_neckinsale",
                      "keanu_reeves":"keanu_reeves",
                      "lauren_cohan":"lauren_cohan",
                      "madonna":"madonna",
                      "mindy_kaling":"mindy_kaling",
                      "simon_pegg":"simon_pegg",
                      "sofia_vergara":"sofia_vergara",
                      "will smith":"will smith"}
def draw_test(name, pred, im):
  face = face_detect_dict[str(pred)]
  BLACK = [0,0,0]
  expanded_image = cv2.copyMakeBorder(im,80,0,0,100,cv2.BORDER_CONSTANT, value=BLACK)
  cv2.putText(expanded_image,face,(20,60),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2)
  cv2.imshow(name, expanded_image)

def getRandomImage(path):
  """function loads a random images from a random folder in our test path """
  folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path))) 
  random_directory = np.random.randint(0,1en(folders))
  path_class = folders[random_directory]
  print("Class - " + face_detect_dict_n[str(path_class)])
  file_path = path + path_class
  file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))] 
  random_file_index = np.random.randint(0,1en(file_names))
  image_name = file_names[random_file_index]
  return cv2.imread(file_path+"/"+image_name)

for i in range(0,20):
  input_im = getRandomImage("14-celebrity-faces-dataset/data/val/")
  input_original = input_im.copy()
  input_original = cv2.resize(input_original, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_LINEAR)
)
  input_im = cv2.resize(input_im, (224, 224), interpolation = cv2.INTER_LINEAR) 
  input_im = input_im / 255.
  input_im = input_im.reshape(1,224,224,3)

  # Get Prediction
  print(classifier.predict(input_im, 1, verbose = 0))
  res = np.argmax(classifier.predict(input_im, 1, verbose = 0), axis=1)

  # Show image with predicted cLass
  draw test("Prediction", res, input original) 
  cv2.waitKey(0)
cv2.destrovAllWindows()

